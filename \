use std::{iter::Peekable, str::Chars};

use crate::lexer::{
    error::LexerError,
    token::{DelimiterType, KeywordType, OperatorType, Token, TokenType},
};

pub struct Lexer<'a> {
    pub source: &'a str,
    pub chars: Peekable<Chars<'a>>,
    pub line: u32,
    pub column: u32,
}

#[allow(unused)]
impl<'a> Lexer<'a> {
    pub fn new(source: &'a str) -> Self {
        Self {
            source,
            chars: source.chars().peekable(),
            line: 1,
            column: 0,
        }
    }

    fn peek(&mut self) -> Option<&char> {
        self.chars.peek()
    }

    fn advance(&mut self) -> Option<char> {
        let current_char = self.chars.next()?;
        match current_char {
            '\n' => {
                self.line += 1;
                self.column = 0;
            }
            c => {
                self.column += 1;
            }
        }
        Some(current_char)
    }

    fn next_token(&mut self) -> Result<Option<Token>, LexerError> {
        self.skip_non_tokens();
        let start_line = self.line;
        let start_column = self.column;
        let current = match self.peek() {
            Some(c) => *c,
            None => return Ok(None),
        };

        match current {
            c if c.is_alphanumeric() || c == '_' => {
                Ok(self.tokenize_identifier_or_keyword(start_line, start_column))
            }

            c if c.is_digit(10) => self.tokenize_number(start_line, start_column).map(Some),

            operator @ ('=' | '+' | '-' | '*' | '/' | '^' | '.') => {
                self.advance();
                Ok(Self::tokenize_operator(operator, start_line, start_column))
            }

            delimiter @ ('(' | ')' | '[' | ']' | '<' | '>' | ',' | ':' | '|') => {
                self.advance();
                Ok(Self::tokenize_delimiter(
                    delimiter,
                    start_line,
                    start_column,
                ))
            }

            _ => {
                self.advance();
                Err(LexerError::UnexpectedCharacter {
                    line: start_line,
                    column: start_column,
                    character: current,
                })
            }
        }
    }

    fn tokenize_identifier_or_keyword(&mut self, line: u32, column: u32) -> Option<Token> {
        let mut identifier = String::new();

        while let Some(&c) = self.peek() {
            if c.is_alphanumeric() || c == '_' {
                identifier.push(c);
                self.advance();
            } else {
                break;
            }
        }

        let token_type = match identifier.as_str() {
            "solve" => TokenType::Keyword(KeywordType::Solve),
            "let" => TokenType::Keyword(KeywordType::Let),
            "in" => TokenType::Keyword(KeywordType::In),
            _ => TokenType::Identifier(identifier.clone()),
        };

        Some(Token {
            token_type,
            literal: identifier,
            line,
            column,
        })
    }

    fn tokenize_number(&mut self, line: u32, column: u32) -> Result<Token, LexerError> {
        let mut literal = String::new();
        let mut has_decimal = false;

        while let Some(&c) = self.peek() {
            if c.is_digit(10) {
                literal.push(c);
                self.advance();
            } else if c == '.' && !has_decimal {
                literal.push(c);
                self.advance();
                has_decimal = true;
            } else {
                break;
            }
        }

        if literal.is_empty() || (literal.len() == 1 && literal.starts_with('.')) {
            return Err(LexerError::InvalidNumber {
                line,
                column,
                literal,
            });
        }

        let value: f64 = match literal.parse() {
            Ok(val) => val,
            Err(_) => {
                return Err(LexerError::InvalidNumber {
                    line,
                    column,
                    literal,
                });
            }
        };

        Ok(Token {
            token_type: TokenType::Number(value),
            literal,
            line,
            column,
        })
    }

    fn tokenize_delimiter(delimiter: char, line: u32, column: u32) -> Option<Token> {
        let literal = delimiter.to_string();
        let token_type = match delimiter {
            '(' => TokenType::Delimiter(DelimiterType::LParen),
            ')' => TokenType::Delimiter(DelimiterType::RParen),
            '[' => TokenType::Delimiter(DelimiterType::LBracket),
            ']' => TokenType::Delimiter(DelimiterType::RBracket),
            '<' => TokenType::Delimiter(DelimiterType::LChevron),
            '>' => TokenType::Delimiter(DelimiterType::RChevron),
            ',' => TokenType::Delimiter(DelimiterType::Comma),
            ':' => TokenType::Delimiter(DelimiterType::Colon),
            '|' => TokenType::Delimiter(DelimiterType::Pipe),
            _ => return None,
        };

        Some(Token {
            token_type,
            literal,
            line,
            column,
        })
    }

    fn tokenize_operator(operator: char, line: u32, column: u32) -> Option<Token> {
        let literal = operator.to_string();
        let token_type = match operator {
            '=' => TokenType::Operator(OperatorType::Equals),
            '+' => TokenType::Operator(OperatorType::Plus),
            '-' => TokenType::Operator(OperatorType::Minus),
            '*' => TokenType::Operator(OperatorType::Multiply),
            '/' => TokenType::Operator(OperatorType::Divide),
            '^' => TokenType::Operator(OperatorType::Power),
            '.' => TokenType::Operator(OperatorType::Dot),
            _ => return None,
        };

        Some(Token {
            token_type,
            literal,
            line,
            column,
        })
    }

    fn skip_non_tokens(&mut self) {
        loop {
            let current_char = self.peek();
            match current_char {
                Some(c) if c.is_whitespace() => {
                    self.advance();
                }
                Some('#') => {
                    self.advance();
                    while let Some(&c) = self.peek() {
                        if c == '\n' {
                            self.advance();
                            break;
                        }
                        self.advance();
                    }
                }
                _ => break,
            }
        }
    }
}
